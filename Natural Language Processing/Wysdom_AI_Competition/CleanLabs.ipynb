{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CleanLabs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYaPU1YPapr-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "import xgboost as XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySa9N0jYa0Ib",
        "outputId": "2d3f5dcb-af13-4b98-83fd-2e898d690926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project_path = '/content/drive/MyDrive/NLP/'\n",
        " "
      ],
      "metadata": {
        "id": "G86-hPJpbWQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(project_path + 'public_data.csv')\n",
        "df_test = pd.read_csv(project_path + 'input_data.csv') \n",
        "########## For people running locally#####\n",
        "#emails_df2 = pd.read_csv('enron_classification_df.csv') "
      ],
      "metadata": {
        "id": "8SyT4urnbWy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.read_csv(\"public_data.csv\")\n",
        "print(df.info())\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "X = df['message']\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer(min_df=.01, max_df=.8, ngram_range=[1,3], max_features=300, stop_words='english')\n",
        "\n",
        "pipe = Pipeline([('vec', vectorizer),  ('clf', DecisionTreeClassifier(random_state=223))])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "pred_val = pipe.predict(X_val)\n",
        "print(confusion_matrix(y_val, pred_val))\n",
        "print(classification_report(y_val, pred_val))\n",
        "\n",
        "\n",
        "from sklearn.metrics.cluster import adjusted_rand_score, adjusted_mutual_info_score\n",
        "\n",
        "ari = adjusted_rand_score(y_val, pred_val)\n",
        "ami = adjusted_mutual_info_score(y_val, pred_val, average_method='arithmetic')\n",
        "\n",
        "print(\"ARI: {}\".format(ari))\n",
        "print(\"AMI: {}\".format(ami))\n",
        "\n",
        "\n",
        "## Kaggle Predictions\n",
        "\n",
        "\n",
        "#df_test = pd.read_csv('input_data.csv')\n",
        "df_test.info()\n",
        "df_test.head()\n",
        "\n",
        "pred_test = pipe.predict(df_test['message'])\n",
        "\n",
        "my_submission = pd.DataFrame({'Id': df_test['id'], 'label': pred_test})\n",
        "print(my_submission.head())\n",
        "\n",
        "# NOTE: after saving the CSV file, be sure to zip the file before submitting to the competition website!\n",
        "my_submission.to_csv('answers.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4eNUPTRbY6w",
        "outputId": "7f84a3de-3cb9-4749-b2d9-f8b7b65e4ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11623 entries, 0 to 11622\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   id       11623 non-null  int64 \n",
            " 1   message  11623 non-null  object\n",
            " 2   label    11623 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 272.5+ KB\n",
            "None\n",
            "     id                                    message              label\n",
            "0  3343    1 \\t pesto drizzle over grilled chicken   orderpizzaintent\n",
            "1  2959    1 \\t pesto drizzle over grilled chicken   orderpizzaintent\n",
            "2   891                             1 agua frescas   orderdrinkintent\n",
            "3  1638  1 agua frescas and 1 classic caesar salad   ordersaladintent\n",
            "4   520                  1 bacon smokehouse burger  orderburgerintent\n",
            "(9298,)\n",
            "(9298,)\n",
            "(2325,)\n",
            "(2325,)\n",
            "[[ 45   0   0 ...   0   0   0]\n",
            " [  0   1   0 ...   0   0   0]\n",
            " [  0   0 168 ...   0   0   1]\n",
            " ...\n",
            " [  0   0   0 ...  75   0   0]\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [  0   0   1 ...   0   0   5]]\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           bookflight       0.92      0.96      0.94        47\n",
            "          changeorder       1.00      0.17      0.29         6\n",
            " changeseatassignment       0.87      0.93      0.90       181\n",
            "         checkbalance       0.95      0.94      0.95        66\n",
            "     checkclaimstatus       0.98      0.96      0.97        94\n",
            "checkoffereligibility       0.38      0.69      0.49        13\n",
            "    checkserverstatus       0.87      1.00      0.93        27\n",
            "         closeaccount       1.00      0.75      0.86         8\n",
            "        disputecharge       0.83      0.52      0.64        46\n",
            "        expensereport       0.95      0.92      0.94        64\n",
            "      getboardingpass       1.00      1.00      1.00       136\n",
            " getinformationintent       0.79      0.57      0.66        46\n",
            "        getpromotions       0.00      0.00      0.00         3\n",
            "  getproofofinsurance       0.98      0.99      0.98       195\n",
            "     getroutingnumber       0.89      1.00      0.94         8\n",
            "          getseatinfo       0.60      0.39      0.48        38\n",
            " orderbreakfastintent       0.00      0.00      0.00         6\n",
            "    orderburgerintent       0.42      0.32      0.36        56\n",
            "          orderchecks       0.50      0.57      0.53         7\n",
            "   orderdessertintent       0.81      0.39      0.53        54\n",
            "     orderdrinkintent       0.54      0.87      0.67       161\n",
            "     orderpizzaintent       0.88      0.84      0.86       179\n",
            "     ordersaladintent       0.92      0.81      0.86        80\n",
            "      ordersideintent       0.00      0.00      0.00        23\n",
            "       providereceipt       0.00      0.00      0.00         0\n",
            "          replacecard       0.89      0.44      0.59        18\n",
            "    reportbrokenphone       1.00      0.98      0.99        46\n",
            " reportbrokensoftware       0.85      0.77      0.81        60\n",
            "       reportlostcard       0.80      0.97      0.87        93\n",
            "       softwareupdate       0.88      0.74      0.80        58\n",
            "           startorder       0.35      0.65      0.46        46\n",
            "   startserviceintent       0.98      0.98      0.98       315\n",
            "            stoporder       0.00      0.00      0.00         2\n",
            "        transfermoney       0.95      0.84      0.89        44\n",
            "        updateaddress       1.00      0.99      0.99        76\n",
            " upgradeserviceintent       0.00      0.00      0.00         4\n",
            "      viewbillsintent       0.45      0.26      0.33        19\n",
            "\n",
            "             accuracy                           0.84      2325\n",
            "            macro avg       0.68      0.63      0.63      2325\n",
            "         weighted avg       0.85      0.84      0.83      2325\n",
            "\n",
            "ARI: 0.7994905638256695\n",
            "AMI: 0.8195614878609371\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2906 entries, 0 to 2905\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   id       2906 non-null   int64 \n",
            " 1   message  2906 non-null   object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 45.5+ KB\n",
            "      Id               label\n",
            "0  12123    orderdrinkintent\n",
            "1    244    orderpizzaintent\n",
            "2   8221      reportlostcard\n",
            "3  12856  startserviceintent\n",
            "4  12108       expensereport\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cleanlab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F25VGvsEbrOt",
        "outputId": "3d4e587e-ca7e-4d70-9102-1a6f4d09209a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cleanlab\n",
            "  Downloading cleanlab-1.0.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cleanlab) (1.4.1)\n",
            "Requirement already satisfied: tqdm>=4.53.0 in /usr/local/lib/python3.7/dist-packages (from cleanlab) (4.63.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from cleanlab) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from cleanlab) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->cleanlab) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->cleanlab) (3.1.0)\n",
            "Installing collected packages: cleanlab\n",
            "Successfully installed cleanlab-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['message']"
      ],
      "metadata": {
        "id": "iNIHe0gCcDAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from numpy.random import multivariate_normal\n",
        "import scipy\n",
        "import warnings\n",
        "import pytest\n",
        "import numpy as np\n",
        "from cleanlab.classification import LearningWithNoisyLabels\n",
        "from cleanlab.noise_generation import generate_noise_matrix_from_trace\n",
        "from cleanlab.noise_generation import generate_noisy_labels\n",
        "from cleanlab.latent_algebra import compute_inv_noise_matrix\n"
      ],
      "metadata": {
        "id": "CRLRbeitbzzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "def label_encoder(data):\n",
        "    class_le = LabelEncoder()    \n",
        "    h = class_le.fit_transform(df['label'].astype(str))\n",
        "    return h"
      ],
      "metadata": {
        "id": "i3EMSeSKnz_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_le = LabelEncoder() "
      ],
      "metadata": {
        "id": "8Hnl7bPZnz_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = class_le.fit_transform(df['label'].astype(str))\n"
      ],
      "metadata": {
        "id": "4h65gsCbnz_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "fXU2LcKHcGyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute p(true_label=k)\n",
        "py = np.bincount(y_train) / float(len(y_train))\n",
        "\n",
        "noise_matrix = generate_noise_matrix_from_trace(\n",
        "    37,\n",
        "    trace=0.9*37,\n",
        "    py=py,\n",
        "    valid_noise_matrix=True,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "# Generate our noisy labels using the noise_matrix.\n",
        "s = generate_noisy_labels(y_train, noise_matrix)\n",
        "ps = np.bincount(s) / float(len(s))\n"
      ],
      "metadata": {
        "id": "DfFS5KdLcJLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et9Z_C65-y7C",
        "outputId": "921a3b84-5d96-46f6-8672-8fb6a1a656d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([28,  5, 13, ..., 15, 20,  2])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorizer = TfidfVectorizer(sublinear_tf=False,smooth_idf=True, max_df=0.9,ngram_range=[1,5], stop_words='english', use_idf=True)"
      ],
      "metadata": {
        "id": "ixt09DX2cRqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorizer = TfidfVectorizer(sublinear_tf=False,smooth_idf=True, max_df=0.9,ngram_range=[1,5], use_idf=False)"
      ],
      "metadata": {
        "id": "BJEec0bv9R_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(min_df=.01, max_df=.8, ngram_range=[1,3], max_features=300)"
      ],
      "metadata": {
        "id": "acQMvUfPwRxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LlxrPquO2ekj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQIc18Jv2hTb",
        "outputId": "c2d44c2b-217f-4131-983b-e2ca84cef1db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<9298x226 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 70967 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_val = vectorizer.fit_transform(X_val)"
      ],
      "metadata": {
        "id": "80fJ2doTcUsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Dh67GYt2GT2",
        "outputId": "458f4b76-a217-43b0-aea0-13ff39fe3e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<9298x226 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 70967 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B43Q15wz_clb",
        "outputId": "8ba0a32f-8d83-4bfb-e52c-af3a4c1e45d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<2325x224 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 17568 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#count_vect_df = pd.DataFrame(X_train.todense(), columns=vectorizer.get_feature_names())"
      ],
      "metadata": {
        "id": "RRXK2L6410Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([X_train, count_vect_df], axis=1)"
      ],
      "metadata": {
        "id": "0tmqX6xl2OIr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "131d11f6-1c05-4cc9-92dc-41956e46c062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-025b6e43447d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_vect_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'count_vect_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cleanlab.latent_estimation import estimate_cv_predicted_probabilities\n",
        "from cleanlab.pruning import get_noise_indices\n",
        "# Find the indices of label errors in 2 lines of code.\n",
        "\n",
        "probabilities = estimate_cv_predicted_probabilities(\n",
        "    X_train, \n",
        "    s, \n",
        "    clf=RandomForestClassifier(),\n",
        ")\n"
      ],
      "metadata": {
        "id": "ntdOia3mcWMO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "f1a2625a-8089-4002-dda9-50fc8c8bfe3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-8f32028b0291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/cleanlab/latent_estimation.py\u001b[0m in \u001b[0;36mestimate_cv_predicted_probabilities\u001b[0;34m(X, labels, clf, cv_n_folds, seed)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mcv_n_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_n_folds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m     )[-1]\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/cleanlab/latent_estimation.py\u001b[0m in \u001b[0;36mestimate_py_noise_matrices_and_cv_pred_proba\u001b[0;34m(X, s, clf, cv_n_folds, thresholds, converge_latent_estimates, py_method, seed)\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0mcv_n_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_n_folds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0mthresholds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m         \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m     )\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/cleanlab/latent_estimation.py\u001b[0m in \u001b[0;36mestimate_confident_joint_and_cv_pred_proba\u001b[0;34m(X, s, clf, cv_n_folds, thresholds, seed, calibrate)\u001b[0m\n\u001b[1;32m    596\u001b[0m       (joint counts matrix, predicted probability matrix)\"\"\"\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0massert_inputs_are_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m     \u001b[0;31m# Number of classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/cleanlab/util.py\u001b[0m in \u001b[0;36massert_inputs_are_valid\u001b[0;34m(X, s, psx)\u001b[0m\n\u001b[1;32m     53\u001b[0m     check_X_y(\n\u001b[1;32m     54\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [9298, 2325]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_error_indices = get_noise_indices(\n",
        "    s = s, \n",
        "    psx = probabilities, \n",
        ")"
      ],
      "metadata": {
        "id": "jiq0tvVAcZBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_cl_both = get_noise_indices(\n",
        "            s, probabilities, prune_method='both')"
      ],
      "metadata": {
        "id": "wUtVymO7cbVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train2 = vectorizer.inverse_transform(X_train)\n",
        "X_val2 = vectorizer.inverse_transform(X_val)"
      ],
      "metadata": {
        "id": "8WxS8wElpunK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "oPuZKDxQ1aGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_cl_both"
      ],
      "metadata": {
        "id": "jxUyjj4tcgr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Wad_dis = class_le.inverse_transform(s)\n",
        "Wad_dis2 = class_le.inverse_transform(y_val)\n",
        "omg_pls = class_le.inverse_transform(y_train)"
      ],
      "metadata": {
        "id": "BPFwDIrKclP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "C66YNTA3wx0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from __future__ import print_function, absolute_import, division, unicode_literals, with_statement\n",
        "# from numpy.random import multivariate_normal\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# import numpy as np\n",
        "\n",
        "\n",
        "# import cleanlab\n",
        "# from cleanlab.noise_generation import generate_noise_matrix_from_trace, generate_noisy_labels\n",
        "# from cleanlab.util import print_noise_matrix\n",
        "# from cleanlab.latent_estimation import estimate_confident_joint_and_cv_pred_proba, estimate_latent\n",
        "# from cleanlab.pruning import get_noise_indices\n",
        "# from cleanlab.classification import LearningWithNoisyLabels"
      ],
      "metadata": {
        "id": "CLDKJMJhsbJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confident_joint, psx = estimate_confident_joint_and_cv_pred_proba(X_train, s, seed=42)\n",
        "# est_py, est_noise_matrix, est_inverse_noise_matrix = estimate_latent(confident_joint, s)\n",
        "# idx_errors = get_noise_indices(s, psx)"
      ],
      "metadata": {
        "id": "Enh8XSdKrNVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(project_path + 'public_data.csv')"
      ],
      "metadata": {
        "id": "8xHKq-TfclR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['message']\n",
        "y = df['label']"
      ],
      "metadata": {
        "id": "yvdVf9APdfIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "owmUFEC5diFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yy = {'Noise':baseline_cl_both,'label_thingy':s,'inversed':Wad_dis,'xtraincompare':X_train2,'realxtrain':X_train,'ytrain':omg_pls}\n",
        "see_df = pd.DataFrame(yy)"
      ],
      "metadata": {
        "id": "cgr7mue3cguC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tt = {'xval':X_val,'yval':y_val,'truelab':Wad_dis2}\n",
        "see_df2 = pd.DataFrame(tt)"
      ],
      "metadata": {
        "id": "qOItJsLSeEfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "see_df"
      ],
      "metadata": {
        "id": "EIMZsHApd9MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "see_df2"
      ],
      "metadata": {
        "id": "TkABXJWheJuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "see_df.to_csv('ehhh.csv', index=False)"
      ],
      "metadata": {
        "id": "NQowXmY3eN_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "see_df2.to_csv('Yval.csv', index=False)"
      ],
      "metadata": {
        "id": "szZOXEu8ePQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "a2G7kdwT8ghH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "z-zlqeoo8gjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P673UnND8glk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from cleanlab.latent_estimation import (\n",
        "  estimate_latent, estimate_confident_joint_and_cv_pred_proba\n",
        ")\n",
        "\n",
        "# Compute the confident joint and psx (n x m predicted probabilities matrix),\n",
        "# for n examples, m classes.\n",
        "confident_joint, psx = estimate_confident_joint_and_cv_pred_proba(\n",
        "    X=X_train, \n",
        "    s=s,\n",
        "    clf=RandomForestClassifier(), # default, you can use any classifier\n",
        ")\n",
        "\n",
        "# Estimate the latent statistics (distributions)\n",
        "#  - Latent Prior: est_py is the array p(y)\n",
        "#  - Noisy Channel / Noise Transition Matrix: est_nm is the matrix P(s|y) \n",
        "#  - Inverse Noise Matrix: est_inv is the matrix P(y|s)\n",
        "est_py, est_nm, est_inv = estimate_latent(\n",
        "    confident_joint, s=s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btFiDV3d8gn8",
        "outputId": "50679c23-d6f2-4ac0-f285-62bdcfdab0e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/cleanlab/latent_algebra.py:253: RuntimeWarning: invalid value encountered in true_divide\n",
            "  py = inverse_noise_matrix.diagonal() / noise_matrix.diagonal() * ps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "est_inv[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3KfX8bV-Ros",
        "outputId": "0e0c3706-f659-4834-c079-31888d209e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.78070175, 0.02702703, 0.0026738 , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01204819, 0.        , 0.00393701,\n",
              "       0.00414938, 0.00591716, 0.        , 0.        , 0.        ,\n",
              "       0.00515464, 0.        , 0.        , 0.02083333, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.01492537, 0.03846154,\n",
              "       0.        , 0.00469484, 0.        , 0.00273224, 0.00471698,\n",
              "       0.00440529, 0.        , 0.03703704, 0.00497512, 0.00308642,\n",
              "       0.        , 0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cleanlab.latent_estimation import (\n",
        "    estimate_py_noise_matrices_and_cv_pred_proba\n",
        ")\n",
        "\n",
        "est_py, est_nm, est_inv, confident_joint, psx = (\n",
        "    estimate_py_noise_matrices_and_cv_pred_proba(\n",
        "        X=X_train,\n",
        "        s=s,\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNwOiJ6f9-sl",
        "outputId": "cba32973-6eb8-4952-b418-ce2709fb0abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/cleanlab/latent_algebra.py:253: RuntimeWarning: invalid value encountered in true_divide\n",
            "  py = inverse_noise_matrix.diagonal() / noise_matrix.diagonal() * ps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(est_inv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIyhxpX59vqW",
        "outputId": "884b22b1-4c8b-405f-e871-b6aab61529ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tHOb-XX8pbi",
        "outputId": "685d6bcc-9709-444a-d415-e1b6133b0093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<2325x224 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 17568 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cleanlab.classification import LearningWithNoisyLabels\n",
        "from sklearn.linear_model import LogisticRegression as LogReg\n",
        "rp = LearningWithNoisyLabels(clf=LogReg()) # Pass in any classifier.\n",
        "rp.fit(X_train, y_train)\n",
        "# Estimate the predictions as if you had trained without label errors.\n",
        "pred = rp.predict(X_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "2icEQ_4t-_k6",
        "outputId": "5ef30bf6-d427-41d0-c75d-38014860f0e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-31ee5070d160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Estimate the predictions as if you had trained without label errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/cleanlab/classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m           The test data as a feature matrix.\"\"\"\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mVector\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \"\"\"\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             raise ValueError(\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: X has 224 features, but LogisticRegression is expecting 226 features as input."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import (print_function, absolute_import, division,\n",
        "                        unicode_literals, with_statement)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import numpy as np\n",
        "from cleanlab.classification import LearningWithNoisyLabels\n",
        "from cleanlab.noise_generation import generate_noisy_labels\n",
        "from cleanlab.util import value_counts\n",
        "from cleanlab.latent_algebra import compute_inv_noise_matrix"
      ],
      "metadata": {
        "id": "0hKQymcD88de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['message']\n",
        "y = df['label']"
      ],
      "metadata": {
        "id": "a1pRymV6CWA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "mSNzxYI4Cces"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Seed for reproducibility\n",
        "# seed = 2\n",
        "# clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000)\n",
        "# rp = LearningWithNoisyLabels(clf=clf, seed=seed)\n",
        "# np.random.seed(seed=seed)\n",
        "\n",
        "# # Get iris dataset\n",
        "# iris = datasets.load_iris()\n",
        "# X = iris.data  # we only take the first two features.\n",
        "# y = iris.target\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "try:\n",
        "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "    from matplotlib import pyplot as plt\n",
        "\n",
        "    _ = plt.figure(figsize=(12, 8))\n",
        "    color_list = plt.cm.tab10(np.linspace(0, 1, 6))\n",
        "    _ = plt.scatter(X_train[:, 1], X_train[:, 3],\n",
        "                    color=[color_list[z] for z in y_train], s=50)\n",
        "    ax = plt.gca()\n",
        "    #     plt.axis('off')\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    _ = ax.get_xaxis().set_ticks([])\n",
        "    _ = ax.get_yaxis().set_ticks([])\n",
        "    _ = plt.title(\"Iris dataset (feature 3 vs feature 1)\", fontsize=30)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(\"Plotting is only supported in an iPython interface.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "HYDeNY0pBmoQ",
        "outputId": "6f59e56c-8b82-4e0d-a25d-0da62c329c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'key of type tuple not found and not a MultiIndex'\n",
            "Plotting is only supported in an iPython interface.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYfCSFzbCBI1",
        "outputId": "b2911e94-9735-41b5-a740-1d8d2bea8794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 1, 2, 1, 0, 2, 1, 1, 2, 1, 1, 2, 1, 0, 2, 0, 1, 0, 0, 0, 2,\n",
              "       2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 1, 1, 2, 2, 1, 0, 1, 0, 2, 1, 1, 0,\n",
              "       1, 1, 1, 2, 0, 1, 0, 1, 2, 0, 1, 0, 0, 0, 2, 2, 0, 0, 2, 2, 1, 2,\n",
              "       1, 1, 2, 0, 2, 2, 2, 0, 2, 0, 0, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2,\n",
              "       1, 2, 1, 0, 1, 1, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 0, 2, 2, 0, 1,\n",
              "       0, 2, 1, 0, 2, 1, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate lots of noise.\n",
        "noise_matrix = np.array([\n",
        "    [0.5, 0.0, 0.0],\n",
        "    [0.5, 1.0, 0.5],\n",
        "    [0.0, 0.0, 0.5],\n",
        "])\n",
        "\n",
        "py = value_counts(y_train)\n",
        "# Create noisy labels\n",
        "s = generate_noisy_labels(y_train, noise_matrix)\n",
        "\n",
        "try:\n",
        "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "    from matplotlib import pyplot as plt\n",
        "\n",
        "    _ = plt.figure(figsize=(15, 8))\n",
        "    color_list = plt.cm.tab10(np.linspace(0, 1, 6))\n",
        "    for k in range(len(np.unique(y_train))):\n",
        "        X_k = X_train[y_train == k]  # data for class k\n",
        "        _ = plt.scatter(\n",
        "            X_k[:, 1],\n",
        "            X_k[:, 3],\n",
        "            color=[color_list[noisy_label] for noisy_label in s[y_train == k]],\n",
        "            s=200,\n",
        "            marker=r\"${a}$\".format(a=str(k)),\n",
        "            linewidth=1,\n",
        "        )\n",
        "    _ = plt.scatter(\n",
        "        x=X_train[s != y_train][:, 1],\n",
        "        y=X_train[s != y_train][:, 3],\n",
        "        color=[color_list[z] for z in s],\n",
        "        s=400,\n",
        "        facecolors='none',\n",
        "        edgecolors='black',\n",
        "        linewidth=2,\n",
        "        alpha=0.5,\n",
        "    )\n",
        "    ax = plt.gca()\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    _ = ax.get_xaxis().set_ticks([])\n",
        "    _ = ax.get_yaxis().set_ticks([])\n",
        "    _ = plt.title(\"Iris dataset (features 3 and 1). Label errors circled.\",\n",
        "                  fontsize=30)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(\"Plotting is only supported in an iPython interface.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "71Ove9s1Bqvu",
        "outputId": "7b2908ee-6571-4860-95a8-87ac67bec282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-4c230bb12f59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Create noisy labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_noisy_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/cleanlab/noise_generation.py\u001b[0m in \u001b[0;36mgenerate_noisy_labels\u001b[0;34m(y, noise_matrix, verbose)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m# Counts of pairs (s, y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mcount_joint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnoise_matrix\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0;31m# Remove diagonal entries as they do not involve flipping of labels.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_diagonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_joint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,3) (37,) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('WITHOUT confident learning,', end=\" \")\n",
        "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000)\n",
        "_ = clf.fit(X_train, s)\n",
        "pred = clf.predict(X_test)\n",
        "print(\"Iris dataset test accuracy:\", round(accuracy_score(pred, y_test), 2))\n",
        "\n",
        "print(\"\\nNow we show improvement using cleanlab to characterize the noise\")\n",
        "print(\"and learn on the data that is (with high confidence) labeled correctly.\")\n",
        "print()\n",
        "print('WITH confident learning (noise matrix given),', end=\" \")\n",
        "_ = rp.fit(X_train, s, noise_matrix=noise_matrix)\n",
        "pred = rp.predict(X_test)\n",
        "print(\"Iris dataset test accuracy:\", round(accuracy_score(pred, y_test), 2))\n",
        "\n",
        "print('WITH confident learning (noise / inverse noise matrix given),', end=\" \")\n",
        "inv = compute_inv_noise_matrix(py, noise_matrix)\n",
        "_ = rp.fit(X_train, s, noise_matrix=noise_matrix, inverse_noise_matrix=inv)\n",
        "pred = rp.predict(X_test)\n",
        "print(\"Iris dataset test accuracy:\", round(accuracy_score(pred, y_test), 2))\n",
        "\n",
        "print('WITH confident learning noise not given,', end=\" \")\n",
        "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000)\n",
        "rp = LearningWithNoisyLabels(clf=clf, seed=seed)\n",
        "_ = rp.fit(X_train, s)\n",
        "pred = rp.predict(X_test)\n",
        "print(\"Iris dataset test accuracy:\", round(accuracy_score(pred, y_test), 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJPcQnPBBsob",
        "outputId": "2cc5d9a8-2758-41c8-fd90-958f4b6bee4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WITHOUT confident learning, Iris dataset test accuracy: 0.6\n",
            "\n",
            "Now we show improvement using cleanlab to characterize the noise\n",
            "and learn on the data that is (with high confidence) labeled correctly.\n",
            "\n",
            "WITH confident learning (noise matrix given), Iris dataset test accuracy: 0.83\n",
            "WITH confident learning (noise / inverse noise matrix given), Iris dataset test accuracy: 0.83\n",
            "WITH confident learning noise not given, Iris dataset test accuracy: 0.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    \"prune_method\": [\"prune_by_noise_rate\", \"prune_by_class\", \"both\"],\n",
        "    \"converge_latent_estimates\": [True, False],\n",
        "}\n",
        "\n",
        "# Fit LearningWithNoisyLabels across all parameter settings.\n",
        "params = ParameterGrid(param_grid)\n",
        "scores = []\n",
        "for param in params:\n",
        "    clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000)\n",
        "    rp = LearningWithNoisyLabels(clf=clf, n_jobs=1, **param)\n",
        "    _ = rp.fit(X_train, s)  # s is the noisy y_train labels\n",
        "    scores.append(accuracy_score(rp.predict(X_test), y_test))\n",
        "\n",
        "# Print results sorted from best to least\n",
        "for i in np.argsort(scores)[::-1]:\n",
        "    print(\"Param settings:\", params[i])\n",
        "    print(\n",
        "        \"Iris dataset test accuracy (using confident learning):\\t\",\n",
        "        round(scores[i], 2),\n",
        "        \"\\n\",\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6QlZEnDBuuN",
        "outputId": "02bc52b7-e942-4f16-f02a-6ac812389e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Param settings: {'prune_method': 'prune_by_class', 'converge_latent_estimates': False}\n",
            "Iris dataset test accuracy (using confident learning):\t 0.83 \n",
            "\n",
            "Param settings: {'prune_method': 'prune_by_class', 'converge_latent_estimates': True}\n",
            "Iris dataset test accuracy (using confident learning):\t 0.83 \n",
            "\n",
            "Param settings: {'prune_method': 'both', 'converge_latent_estimates': False}\n",
            "Iris dataset test accuracy (using confident learning):\t 0.8 \n",
            "\n",
            "Param settings: {'prune_method': 'both', 'converge_latent_estimates': True}\n",
            "Iris dataset test accuracy (using confident learning):\t 0.8 \n",
            "\n",
            "Param settings: {'prune_method': 'prune_by_noise_rate', 'converge_latent_estimates': False}\n",
            "Iris dataset test accuracy (using confident learning):\t 0.77 \n",
            "\n",
            "Param settings: {'prune_method': 'prune_by_noise_rate', 'converge_latent_estimates': True}\n",
            "Iris dataset test accuracy (using confident learning):\t 0.77 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    \"prune_method\": [\"prune_by_noise_rate\", \"prune_by_class\", \"both\"],\n",
        "    \"converge_latent_estimates\": [True, False],\n",
        "}\n",
        "\n",
        "# Fit LearningWithNoisyLabels across all parameter settings.\n",
        "params = ParameterGrid(param_grid)\n",
        "scores = []\n",
        "for param in params:\n",
        "    clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000)\n",
        "    rp = LearningWithNoisyLabels(clf=clf, n_jobs=1, **param)\n",
        "    _ = rp.fit(X_train, s)  # s is the noisy y_train labels\n",
        "    scores.append(accuracy_score(rp.predict(X_test), y_test))\n",
        "\n",
        "# Print results sorted from best to least\n",
        "for i in np.argsort(scores)[::-1]:\n",
        "    print(\"Param settings:\", params[i])\n",
        "    print(\n",
        "        \"Iris dataset test accuracy (using confident learning):\\t\",\n",
        "        round(scores[i], 2),\n",
        "        \"\\n\",\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs9Qyq0iBwkY",
        "outputId": "c2bc7d46-2b7e-4b42-eaf3-16ee5946adce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Param settings: {'prune_method': 'prune_by_noise_rate', 'converge_latent_estimates': True}\n",
            "Iris dataset test accuracy (using confident learning):\t 0.87 \n",
            "\n",
            "Param settings: {'prune_method': 'both', 'converge_latent_estimates': False}\n",
            "Iris dataset test accuracy (using confident learning):\t 0.83 \n",
            "\n",
            "Param settings: {'prune_method': 'prune_by_class', 'converge_latent_estimates': False}\n",
            "Iris dataset test accuracy (using confident learning):\t 0.83 \n",
            "\n",
            "Param settings: {'prune_method': 'prune_by_noise_rate', 'converge_latent_estimates': False}\n",
            "Iris dataset test accuracy (using confident learning):\t 0.77 \n",
            "\n",
            "Param settings: {'prune_method': 'both', 'converge_latent_estimates': True}\n",
            "Iris dataset test accuracy (using confident learning):\t 0.77 \n",
            "\n",
            "Param settings: {'prune_method': 'prune_by_class', 'converge_latent_estimates': True}\n",
            "Iris dataset test accuracy (using confident learning):\t 0.77 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}